{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52311a14-12ce-4e16-8beb-f2e2841bee52",
   "metadata": {},
   "source": [
    "Get the per image normalized counts for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1793391f-9b54-48bc-afd1-3e0757860108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from scipy import ndimage\n",
    "# from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e503891-bc21-43e4-839f-4a860b7d0e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 32, 32, 3) dtype=float32 (created by layer 'conv2d_input')>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load trained model here\n",
    "TN_model = tf.keras.models.load_model('models/TN_model_with_new_data.h5')\n",
    "# look at the input shape\n",
    "TN_model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5cfb7de-63c9-4654-b427-9eac413bc4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_input (InputLayer)   [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 30, 30, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 15, 15, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 13, 13, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " New_dropout (Dropout)       (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " Flatten2 (Flatten)          (None, 2304)              0         \n",
      "                                                                 \n",
      " New_Dense (Dense)           (None, 512)               1180160   \n",
      "                                                                 \n",
      " New_Activation (Activation)  (None, 512)              0         \n",
      "                                                                 \n",
      " New_dropout2 (Dropout)      (None, 512)               0         \n",
      "                                                                 \n",
      " New_Dense2 (Dense)          (None, 1)                 513       \n",
      "                                                                 \n",
      " New_Activation2 (Activation  (None, 1)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,246,241\n",
      "Trainable params: 1,217,601\n",
      "Non-trainable params: 28,640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "TN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bfa9521-9824-4589-8158-80603a2fd425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image and density file location\n",
    "file_path  = 'Preprocessed_valid_data/all_img_density_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a66e8789-2c33-4b16-a2ab-d228fd1347f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contents here\n",
    "folder_contents = os.listdir(file_path)\n",
    "folder_contents.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37f70075-d9da-433a-9348-f57788045cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folder_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1398efa1-9959-4d58-8ff5-28bca40d2db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only the image files\n",
    "val_images = [file for file in folder_contents if file.split(\".\")[0][-3:] != 'map']\n",
    "val_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "964b3ae0-e521-4b3d-b421-d9bbde7e73c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86c94765-2a15-40d6-b309-14eb12f16bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Block0204_2020_06_29.npy (1024, 768, 3)\n",
      "2 Block0204_2020_07_01.npy (1024, 768, 3)\n",
      "3 Block0204_2020_07_02.npy (1024, 768, 3)\n",
      "4 Block0204_2020_07_06.npy (1024, 768, 3)\n",
      "5 Block0204_2020_07_07.npy (1024, 768, 3)\n",
      "6 Block0204_2020_07_08.npy (1024, 768, 3)\n",
      "7 Block0204_2020_07_14.npy (1024, 768, 3)\n",
      "8 Block0204_2020_07_16.npy (1024, 768, 3)\n",
      "9 Block0204_2020_07_17.npy (1024, 768, 3)\n",
      "10 Block0204_2020_07_20.npy (1024, 768, 3)\n",
      "11 Block0204_2020_07_22.npy (1024, 768, 3)\n",
      "12 Block0204_2020_07_23.npy (1024, 768, 3)\n",
      "13 Block0204_2020_08_03.npy (768, 1024, 3)\n",
      "14 Block0204_2020_08_04.npy (768, 1024, 3)\n",
      "15 Block0204_2020_08_06.npy (768, 1024, 3)\n",
      "16 Block0204_2020_08_07.npy (768, 1024, 3)\n",
      "17 Block0204_2020_08_11.npy (768, 1024, 3)\n",
      "18 Block0204_2020_08_12.npy (768, 1024, 3)\n",
      "19 Block0204_2020_08_14.npy (768, 1024, 3)\n",
      "20 Block0204_2020_08_15.npy (768, 1024, 3)\n",
      "21 Block0204_2020_08_17.npy (768, 1024, 3)\n",
      "22 Block0204_2020_08_18.npy (768, 1024, 3)\n",
      "23 Block0204_2020_08_19.npy (768, 1024, 3)\n",
      "24 Block0204_2020_08_21.npy (768, 1024, 3)\n",
      "25 Block0204_2020_08_25.npy (768, 1024, 3)\n",
      "26 Block0204_2020_08_26.npy (768, 1024, 3)\n",
      "27 Block0204_2020_08_27.npy (768, 1024, 3)\n",
      "28 Block0204_2020_08_28.npy (768, 1024, 3)\n",
      "29 Block0204_2020_08_31.npy (768, 1024, 3)\n",
      "30 Block0204_2020_09_02.npy (768, 1024, 3)\n",
      "31 Block0204_2020_09_07.npy (768, 1024, 3)\n",
      "32 Block0204_2020_09_16.npy (768, 1024, 3)\n",
      "CPU times: user 11.4 ms, sys: 34.4 ms, total: 45.8 ms\n",
      "Wall time: 223 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# check the shapes of the image files\n",
    "counter = 0\n",
    "for file in val_images:\n",
    "    load_file = np.load(file_path + '/' + file)\n",
    "    counter = counter + 1\n",
    "    print(counter, file, load_file.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17d7b861-1748-47f4-a801-8ef5c3b9adcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'final_valid_sub_windows_and_counts/Block_24'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the stacked test sub windows path\n",
    "block_number = 'Block_24'\n",
    "stacked_file_path = os.path.join('final_valid_sub_windows_and_counts/', block_number)\n",
    "stacked_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "527a2956-831b-42c0-9907-b13b0057b0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the contents\n",
    "contents_stacked = os.listdir(stacked_file_path)\n",
    "contents_stacked.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0805bb82-51b3-4c29-8c85-d41e3e30af1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contents_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ce9f9b4-1436-4c6d-b802-eb50e8d25097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only the image files\n",
    "images_stacked = [file for file in contents_stacked if file[:7] == 'val_ims']\n",
    "images_stacked.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1b46fcc-a4d2-48fd-a03b-dbd935a47ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "443a8789-33e2-41e5-98c7-904dde5612e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'val_ims_Block0204_2020_06_29.npy'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_stacked[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f0c6e19-7895-4874-86ac-35ca48e2a228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Block0204_2020_06_29.npy'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_stacked[0].split('val_ims_')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1eb132cd-7d42-455c-b8bd-4313d1c2b98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get the post-hoc prediction\n",
    "def prediction_on_test_data(model, numpy_folder, v_stack_folder, selected_file, stride = 8, kernel_size = 32):\n",
    "#     load the cnn model\n",
    "    \n",
    "# load the image data file\n",
    "    load_image = np.load(numpy_folder + \"/\"+ selected_file)\n",
    "    \n",
    "    # get the image height\n",
    "    img_height = load_image.shape[0]\n",
    "    # get the image weight\n",
    "    img_width = load_image.shape[1]\n",
    "\n",
    "    selected_stacked_file = 'val_ims_' + selected_file\n",
    "    all_test_sub_windows = np.load(v_stack_folder + \"/\"+ selected_stacked_file)\n",
    "\n",
    "    # now, to get the predictions, pass the sub windows\n",
    "    test_image_prediction = model.predict(all_test_sub_windows)\n",
    "    \n",
    "    # density map\n",
    "    Density_map = np.zeros((img_height, img_width))\n",
    "\n",
    "    # counts map\n",
    "    counts_map = np.zeros((img_height, img_width))\n",
    "    \n",
    "    # now, for every window, we will keep adding the values together and also add the counts\n",
    "    counter = 0\n",
    "#     need a counter to move into each predicted value in the pred values list\n",
    "    for ii in range(0, img_height, stride):\n",
    "        for jj in range(0, img_width, stride):\n",
    "#         operations for density map\n",
    "#             get the window of interest\n",
    "            new_window = Density_map[ii:ii + kernel_size,jj:jj+kernel_size]\n",
    "#     fill each with the value c_k\n",
    "            counts_window = np.full((new_window.shape[0], new_window.shape[1]), test_image_prediction[counter])\n",
    "#     get the shapes of this new window\n",
    "            cw_height = counts_window.shape[0]\n",
    "            cw_width = counts_window.shape[1]\n",
    "#         Do c_k/r_2\n",
    "            counts_window_new = counts_window/(cw_height*cw_width)\n",
    "#     This is the value in the window now\n",
    "            value_window = counts_window_new\n",
    "#     place the values in the corrsponding area of the density map\n",
    "            Density_map[ii:ii + kernel_size,jj:jj+kernel_size] = new_window + value_window\n",
    "\n",
    "#         Let's now focus on capturing the counts of the windows\n",
    "            new_window_c = counts_map[ii:ii + kernel_size,jj:jj+kernel_size]\n",
    "#     get the counts area\n",
    "            count = np.ones((new_window_c.shape[0], new_window_c.shape[1]))\n",
    "#     keep adding the counts to reflect the addition of densities\n",
    "            counts_map[ii:ii + kernel_size,jj:jj+kernel_size] = new_window_c + count\n",
    "#     increase the counter\n",
    "            counter = counter + 1\n",
    "            \n",
    "#         get the normalized count\n",
    "    normalized_counts = np.divide(Density_map, counts_map)\n",
    "    \n",
    "#     entire count on the test set\n",
    "    pred_on_test = np.sum(normalized_counts)\n",
    "    \n",
    "#     return the predicted value\n",
    "    return(pred_on_test, normalized_counts, selected_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06ff122e-b0c7-4ed4-988b-0a316732d4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.8 s, sys: 8.21 s, total: 44 s\n",
      "Wall time: 43.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the predictions for valid data\n",
    "\n",
    "# save density map path\n",
    "dense_path = \"predicted_count_maps_for_valid_files/Block_24\"\n",
    "\n",
    "final_values_preds_names = []\n",
    "for file in val_images:\n",
    "    name = file\n",
    "    preds_value, norm_counts, _ = prediction_on_test_data(TN_model, file_path, stacked_file_path, file, stride = 8, kernel_size = 32)\n",
    "    # save the normalized density maps\n",
    "    np.save(dense_path + '/' + file.split('.')[0] + '_' +  '_norm_map_TN.npy', norm_counts)\n",
    "        # normalized_pred_maps.append(norm_counts)\n",
    "    final_values_preds_names.append((name, preds_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30e5c5dd-6d6f-4c7c-ab9b-b2fb8b1461f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with the predicted values\n",
    "Predicted_values_df = pd.DataFrame(final_values_preds_names, columns = ['Image_name', 'Predicted_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "359b31b0-e5b5-4b97-8bae-634c2ecd4545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_name</th>\n",
       "      <th>Predicted_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Block0204_2020_06_29.npy</td>\n",
       "      <td>2.103025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Block0204_2020_07_01.npy</td>\n",
       "      <td>3.598690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Block0204_2020_07_02.npy</td>\n",
       "      <td>7.005647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Block0204_2020_07_06.npy</td>\n",
       "      <td>9.229449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Block0204_2020_07_07.npy</td>\n",
       "      <td>12.557514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Image_name  Predicted_count\n",
       "0  Block0204_2020_06_29.npy         2.103025\n",
       "1  Block0204_2020_07_01.npy         3.598690\n",
       "2  Block0204_2020_07_02.npy         7.005647\n",
       "3  Block0204_2020_07_06.npy         9.229449\n",
       "4  Block0204_2020_07_07.npy        12.557514"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predicted_values_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8a79cff-ad1a-4c97-adf7-498e1357c8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predicted_values_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bef75bbe-c0e4-45e9-863f-84812a990a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the true validation counts\n",
    "True_valid_counts_df = pd.read_csv(\"True_tassel_counts/test_data/true_test_counts_blk_13.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45845463-16f3-45d1-aab1-c60db31717ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_with_py38_gpu_29)",
   "language": "python",
   "name": "tf_with_py38_gpu_29"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
